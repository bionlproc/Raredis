# model = "allenai/scibert_scivocab_uncased"
# model = "dmis-lab/biobert-v1.1"
# model = "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext"
model = "/project/rvkavu2_uksr/sgu260/RareDis/PURE/outputs/Xuguang_SODNER/pubmedBERT_large/pre_trained_model/"
output_dir = "/project/rvkavu2_uksr/sgu260/RareDis/PURE/outputs/Xuguang_SODNER/pubmedBERT_large/12/relation/"
eval_per_epoch = 10
max_seq_length = 512
negative_label = "no_relation"
do_train = True
train_file = "/project/rvkavu2_uksr/sgu260/RareDis/PURE/Preprocess/entire_sentence/under_512/Xuguang_SODNER_data/new_data/train.json"
train_mode = "random_sorted" #choices=['random', 'sorted', 'random_sorted']
do_eval = True
do_lower_case = True
eval_test = False
eval_with_gold = False
train_batch_size = 8
eval_batch_size = 8
eval_metric = "f1"
learning_rate = 1e-5
num_train_epochs = 7.0
warmup_proportion = 0.1
no_cuda = False
seed = 0
bertadam = False
entity_output_dir = "/project/rvkavu2_uksr/sgu260/RareDis/PURE/outputs/Xuguang_SODNER/pubmedBERT_large/12/entity/"
entity_predictions_dev = "ent_pred_dev.json"
entity_predictions_test = "ent_pred_test.json"
prediction_file = "predictions.json"
task = "raredis"
context_window = 100
add_new_tokens = True