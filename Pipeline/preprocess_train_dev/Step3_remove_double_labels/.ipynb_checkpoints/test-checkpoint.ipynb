{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cfaff3c",
   "metadata": {},
   "source": [
    "# Set up the format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a66b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac37585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = '/Users/XA/Desktop/RareDis_Pipeline/Datasets_with_only_gold_entities/train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "096c81da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for line in open(Path, 'r'):\n",
    "    train.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7ce62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    train[i]['doc_key'] = train[i].pop('doc')\n",
    "    train[i]['sentences'] = train[i].pop('tokens')\n",
    "    train[i]['ner'] = train[i].pop('entities')\n",
    "\n",
    "    train[i]['ner_modified'] = train[i]['ner'].copy()\n",
    "    train[i]['sentences_modified'] = train[i]['sentences'].copy()\n",
    "\n",
    "    train[i].pop('start')\n",
    "    train[i].pop('end')\n",
    "    train[i].pop('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35689c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2intlist(s):\n",
    "    l = []\n",
    "    l.append(int(s.split(',')[0]))\n",
    "    l.append(int(s.split(',')[1]))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f5a76ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert number strings to number lists for ner\n",
    "\n",
    "for i in range(len(train)):\n",
    "    l = []\n",
    "    for j in range(len(train[i]['ner'])):\n",
    "        l_temp = []\n",
    "        for k in range(len(train[i]['ner'][j]['span'])):\n",
    "            l_temp.append(str2intlist(train[i]['ner'][j]['span'][k]))\n",
    "        l_temp.append(train[i]['ner'][j]['type'])\n",
    "        l.append(l_temp)\n",
    "    train[i]['ner'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f422e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert number strings to number lists for ner_modified\n",
    "\n",
    "for i in range(len(train)):\n",
    "    l = []\n",
    "    for j in range(len(train[i]['ner_modified'])):\n",
    "        l_temp = []\n",
    "        for k in range(len(train[i]['ner_modified'][j]['span'])):\n",
    "            l_temp.append(str2intlist(train[i]['ner_modified'][j]['span'][k]))\n",
    "        l_temp.append(train[i]['ner_modified'][j]['type'])\n",
    "        l.append(l_temp)\n",
    "    train[i]['ner_modified'] = l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125c7971",
   "metadata": {},
   "source": [
    "# Remove discontinuous entities with more than 2 fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5a5e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    \n",
    "    indices_to_remove = set()\n",
    "    \n",
    "    for j in range(len(train[i]['ner_modified'])):\n",
    "        if len(train[i]['ner_modified'][j]) >= 4:\n",
    "            indices_to_remove.add(j)\n",
    "            \n",
    "    new_list = [sublist for idx, sublist in enumerate(train[i]['ner_modified']) if idx not in indices_to_remove]\n",
    "    \n",
    "    train[i]['ner_modified'] = new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176a7ccc",
   "metadata": {},
   "source": [
    "# Check non-overlapped and overlapped discontinuous entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d79e0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of non-overlapped fragments for the current entity\n",
    "\n",
    "def num_nonoverlap_fragments_current_entity(ner_lists, current_entitiy_idx): \n",
    "    \n",
    "    num = 0\n",
    "    \n",
    "    if 0 < current_entitiy_idx < len(ner_lists) - 1: # Neither the 1st nor the last entity\n",
    "\n",
    "        for k in range(len(ner_lists[current_entitiy_idx]) - 1): # -1 excludes entity types such as 'SIGN'\n",
    "            \n",
    "            cur_entity_cur_fragment_left_pos = ner_lists[current_entitiy_idx][k][0]\n",
    "            cur_entity_cur_fragment_right_pos = ner_lists[current_entitiy_idx][k][1]\n",
    "\n",
    "            previous_entity_last_fragment_right_pos = ner_lists[current_entitiy_idx-1][-2][1]\n",
    "            next_entity_first_fragment_left_pos = ner_lists[current_entitiy_idx+1][0][0]\n",
    "      \n",
    "            if (previous_entity_last_fragment_right_pos < cur_entity_cur_fragment_left_pos < next_entity_first_fragment_left_pos \n",
    "                and previous_entity_last_fragment_right_pos < cur_entity_cur_fragment_right_pos < next_entity_first_fragment_left_pos):\n",
    "                num += 1\n",
    "                \n",
    "    elif current_entitiy_idx == 0: # 1st entity\n",
    "        \n",
    "        for k in range(len(ner_lists[current_entitiy_idx]) - 1):\n",
    "            \n",
    "            cur_entity_cur_fragment_left_pos = ner_lists[current_entitiy_idx][k][0]\n",
    "            cur_entity_cur_fragment_right_pos = ner_lists[current_entitiy_idx][k][1]\n",
    "\n",
    "            next_entity_first_fragment_left_pos = ner_lists[current_entitiy_idx+1][0][0]\n",
    "            \n",
    "            if (cur_entity_cur_fragment_left_pos < next_entity_first_fragment_left_pos \n",
    "            and cur_entity_cur_fragment_right_pos < next_entity_first_fragment_left_pos):\n",
    "                num += 1\n",
    "                \n",
    "    else: # Last entity\n",
    "        \n",
    "        for k in range(len(ner_lists[current_entitiy_idx]) - 1):\n",
    "            \n",
    "            cur_entity_cur_fragment_left_pos = ner_lists[current_entitiy_idx][k][0]\n",
    "            cur_entity_cur_fragment_right_pos = ner_lists[current_entitiy_idx][k][1]\n",
    "\n",
    "            previous_entity_last_fragment_right_pos = ner_lists[current_entitiy_idx-1][-2][1]\n",
    "            \n",
    "            if (cur_entity_cur_fragment_left_pos > previous_entity_last_fragment_right_pos\n",
    "            and cur_entity_cur_fragment_right_pos > previous_entity_last_fragment_right_pos):\n",
    "                num += 1\n",
    "            \n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ec411be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cur_entity_overlap(ner_lists, current_entitiy_idx, num_nonoverlap_fragments):\n",
    "    if num_nonoverlap_fragments_current_entity(ner_lists, current_entitiy_idx) == len(ner_lists[current_entitiy_idx]) - 1:\n",
    "        return False # All fragments of current entity do not overlap with other entities\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d772e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 6th discontinuous entity in doc_3 is overlapped.\n",
      "The 5th discontinuous entity in doc_4 is non-overlapped.\n",
      "The 12th discontinuous entity in doc_7 is overlapped.\n",
      "The 8th discontinuous entity in doc_8 is non-overlapped.\n",
      "The 13th discontinuous entity in doc_8 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_9 is non-overlapped.\n",
      "The 3th discontinuous entity in doc_14 is overlapped.\n",
      "The 4th discontinuous entity in doc_14 is overlapped.\n",
      "The 5th discontinuous entity in doc_14 is overlapped.\n",
      "The 13th discontinuous entity in doc_25 is overlapped.\n",
      "The 3th discontinuous entity in doc_29 is overlapped.\n",
      "The 4th discontinuous entity in doc_29 is overlapped.\n",
      "The 6th discontinuous entity in doc_29 is non-overlapped.\n",
      "The 13th discontinuous entity in doc_29 is non-overlapped.\n",
      "The 17th discontinuous entity in doc_29 is overlapped.\n",
      "The 18th discontinuous entity in doc_29 is overlapped.\n",
      "The 19th discontinuous entity in doc_29 is overlapped.\n",
      "The 6th discontinuous entity in doc_30 is overlapped.\n",
      "The 9th discontinuous entity in doc_30 is overlapped.\n",
      "The 10th discontinuous entity in doc_30 is overlapped.\n",
      "The 3th discontinuous entity in doc_31 is overlapped.\n",
      "The 17th discontinuous entity in doc_32 is non-overlapped.\n",
      "The 27th discontinuous entity in doc_32 is non-overlapped.\n",
      "The 8th discontinuous entity in doc_35 is overlapped.\n",
      "The 9th discontinuous entity in doc_35 is overlapped.\n",
      "The 5th discontinuous entity in doc_38 is non-overlapped.\n",
      "The 5th discontinuous entity in doc_40 is non-overlapped.\n",
      "The 7th discontinuous entity in doc_42 is overlapped.\n",
      "The 19th discontinuous entity in doc_43 is non-overlapped.\n",
      "The 11th discontinuous entity in doc_47 is overlapped.\n",
      "The 6th discontinuous entity in doc_48 is non-overlapped.\n",
      "The 7th discontinuous entity in doc_48 is overlapped.\n",
      "The 8th discontinuous entity in doc_48 is overlapped.\n",
      "The 19th discontinuous entity in doc_48 is overlapped.\n",
      "The 21th discontinuous entity in doc_48 is overlapped.\n",
      "The 3th discontinuous entity in doc_49 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_49 is overlapped.\n",
      "The 2th discontinuous entity in doc_50 is non-overlapped.\n",
      "The 3th discontinuous entity in doc_50 is overlapped.\n",
      "The 11th discontinuous entity in doc_50 is overlapped.\n",
      "The 12th discontinuous entity in doc_50 is overlapped.\n",
      "The 13th discontinuous entity in doc_50 is overlapped.\n",
      "The 3th discontinuous entity in doc_51 is overlapped.\n",
      "The 4th discontinuous entity in doc_51 is overlapped.\n",
      "The 2th discontinuous entity in doc_53 is overlapped.\n",
      "The 3th discontinuous entity in doc_53 is overlapped.\n",
      "The 4th discontinuous entity in doc_53 is overlapped.\n",
      "The 0th discontinuous entity in doc_54 is non-overlapped.\n",
      "The 1th discontinuous entity in doc_54 is non-overlapped.\n",
      "The 5th discontinuous entity in doc_54 is non-overlapped.\n",
      "The 12th discontinuous entity in doc_54 is non-overlapped.\n",
      "The 20th discontinuous entity in doc_54 is non-overlapped.\n",
      "The 4th discontinuous entity in doc_56 is overlapped.\n",
      "The 7th discontinuous entity in doc_63 is non-overlapped.\n",
      "The 15th discontinuous entity in doc_63 is overlapped.\n",
      "The 16th discontinuous entity in doc_63 is overlapped.\n",
      "The 18th discontinuous entity in doc_63 is overlapped.\n",
      "The 34th discontinuous entity in doc_63 is overlapped.\n",
      "The 6th discontinuous entity in doc_64 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_69 is overlapped.\n",
      "The 3th discontinuous entity in doc_69 is overlapped.\n",
      "The 4th discontinuous entity in doc_69 is overlapped.\n",
      "The 5th discontinuous entity in doc_69 is overlapped.\n",
      "The 3th discontinuous entity in doc_70 is overlapped.\n",
      "The 9th discontinuous entity in doc_70 is overlapped.\n",
      "The 21th discontinuous entity in doc_70 is non-overlapped.\n",
      "The 3th discontinuous entity in doc_76 is overlapped.\n",
      "The 4th discontinuous entity in doc_76 is overlapped.\n",
      "The 10th discontinuous entity in doc_77 is overlapped.\n",
      "The 2th discontinuous entity in doc_83 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_84 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_86 is non-overlapped.\n",
      "The 4th discontinuous entity in doc_86 is non-overlapped.\n",
      "The 11th discontinuous entity in doc_89 is overlapped.\n",
      "The 2th discontinuous entity in doc_94 is overlapped.\n",
      "The 10th discontinuous entity in doc_97 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_98 is non-overlapped.\n",
      "The 12th discontinuous entity in doc_98 is non-overlapped.\n",
      "The 17th discontinuous entity in doc_101 is overlapped.\n",
      "The 18th discontinuous entity in doc_101 is overlapped.\n",
      "The 19th discontinuous entity in doc_101 is overlapped.\n",
      "The 16th discontinuous entity in doc_103 is overlapped.\n",
      "The 17th discontinuous entity in doc_103 is overlapped.\n",
      "The 11th discontinuous entity in doc_112 is non-overlapped.\n",
      "The 17th discontinuous entity in doc_112 is overlapped.\n",
      "The 22th discontinuous entity in doc_112 is overlapped.\n",
      "The 5th discontinuous entity in doc_113 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_118 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_118 is non-overlapped.\n",
      "The 9th discontinuous entity in doc_119 is overlapped.\n",
      "The 7th discontinuous entity in doc_121 is overlapped.\n",
      "The 8th discontinuous entity in doc_121 is overlapped.\n",
      "The 9th discontinuous entity in doc_121 is non-overlapped.\n",
      "The 5th discontinuous entity in doc_127 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_129 is overlapped.\n",
      "The 11th discontinuous entity in doc_136 is overlapped.\n",
      "The 12th discontinuous entity in doc_136 is overlapped.\n",
      "The 13th discontinuous entity in doc_136 is overlapped.\n",
      "The 14th discontinuous entity in doc_136 is overlapped.\n",
      "The 7th discontinuous entity in doc_137 is overlapped.\n",
      "The 4th discontinuous entity in doc_139 is non-overlapped.\n",
      "The 4th discontinuous entity in doc_140 is overlapped.\n",
      "The 5th discontinuous entity in doc_140 is overlapped.\n",
      "The 8th discontinuous entity in doc_142 is overlapped.\n",
      "The 1th discontinuous entity in doc_145 is non-overlapped.\n",
      "The 5th discontinuous entity in doc_148 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_150 is non-overlapped.\n",
      "The 4th discontinuous entity in doc_150 is non-overlapped.\n",
      "The 9th discontinuous entity in doc_150 is overlapped.\n",
      "The 10th discontinuous entity in doc_150 is overlapped.\n",
      "The 12th discontinuous entity in doc_150 is non-overlapped.\n",
      "The 15th discontinuous entity in doc_155 is overlapped.\n",
      "The 16th discontinuous entity in doc_155 is overlapped.\n",
      "The 7th discontinuous entity in doc_161 is non-overlapped.\n",
      "The 23th discontinuous entity in doc_161 is overlapped.\n",
      "The 3th discontinuous entity in doc_162 is overlapped.\n",
      "The 11th discontinuous entity in doc_162 is non-overlapped.\n",
      "The 18th discontinuous entity in doc_162 is non-overlapped.\n",
      "The 14th discontinuous entity in doc_164 is overlapped.\n",
      "The 5th discontinuous entity in doc_167 is overlapped.\n",
      "The 6th discontinuous entity in doc_167 is non-overlapped.\n",
      "The 9th discontinuous entity in doc_167 is non-overlapped.\n",
      "The 9th discontinuous entity in doc_169 is overlapped.\n",
      "The 11th discontinuous entity in doc_171 is overlapped.\n",
      "The 5th discontinuous entity in doc_177 is overlapped.\n",
      "The 6th discontinuous entity in doc_177 is overlapped.\n",
      "The 8th discontinuous entity in doc_177 is overlapped.\n",
      "The 9th discontinuous entity in doc_177 is overlapped.\n",
      "The 10th discontinuous entity in doc_177 is overlapped.\n",
      "The 4th discontinuous entity in doc_178 is overlapped.\n",
      "The 5th discontinuous entity in doc_178 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_178 is non-overlapped.\n",
      "The 23th discontinuous entity in doc_180 is overlapped.\n",
      "The 16th discontinuous entity in doc_184 is overlapped.\n",
      "The 20th discontinuous entity in doc_184 is overlapped.\n",
      "The 21th discontinuous entity in doc_184 is overlapped.\n",
      "The 14th discontinuous entity in doc_185 is overlapped.\n",
      "The 15th discontinuous entity in doc_185 is overlapped.\n",
      "The 4th discontinuous entity in doc_186 is overlapped.\n",
      "The 9th discontinuous entity in doc_186 is overlapped.\n",
      "The 11th discontinuous entity in doc_186 is non-overlapped.\n",
      "The 14th discontinuous entity in doc_186 is non-overlapped.\n",
      "The 16th discontinuous entity in doc_186 is overlapped.\n",
      "The 22th discontinuous entity in doc_186 is non-overlapped.\n",
      "The 1th discontinuous entity in doc_188 is overlapped.\n",
      "The 5th discontinuous entity in doc_189 is overlapped.\n",
      "The 16th discontinuous entity in doc_192 is non-overlapped.\n",
      "The 7th discontinuous entity in doc_194 is non-overlapped.\n",
      "The 12th discontinuous entity in doc_194 is overlapped.\n",
      "The 4th discontinuous entity in doc_195 is non-overlapped.\n",
      "The 28th discontinuous entity in doc_196 is overlapped.\n",
      "The 6th discontinuous entity in doc_199 is non-overlapped.\n",
      "The 7th discontinuous entity in doc_199 is non-overlapped.\n",
      "The 13th discontinuous entity in doc_199 is non-overlapped.\n",
      "The 5th discontinuous entity in doc_200 is non-overlapped.\n",
      "The 14th discontinuous entity in doc_200 is non-overlapped.\n",
      "The 24th discontinuous entity in doc_200 is non-overlapped.\n",
      "The 25th discontinuous entity in doc_200 is overlapped.\n",
      "The 2th discontinuous entity in doc_203 is overlapped.\n",
      "The 20th discontinuous entity in doc_205 is non-overlapped.\n",
      "The 28th discontinuous entity in doc_205 is overlapped.\n",
      "The 5th discontinuous entity in doc_208 is overlapped.\n",
      "The 6th discontinuous entity in doc_208 is overlapped.\n",
      "The 3th discontinuous entity in doc_217 is non-overlapped.\n",
      "The 8th discontinuous entity in doc_219 is non-overlapped.\n",
      "The 22th discontinuous entity in doc_219 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_220 is overlapped.\n",
      "The 11th discontinuous entity in doc_228 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_230 is overlapped.\n",
      "The 2th discontinuous entity in doc_237 is non-overlapped.\n",
      "The 3th discontinuous entity in doc_238 is non-overlapped.\n",
      "The 0th discontinuous entity in doc_246 is overlapped.\n",
      "The 1th discontinuous entity in doc_246 is overlapped.\n",
      "The 1th discontinuous entity in doc_254 is non-overlapped.\n",
      "The 3th discontinuous entity in doc_255 is non-overlapped.\n",
      "The 4th discontinuous entity in doc_255 is non-overlapped.\n",
      "The 14th discontinuous entity in doc_255 is non-overlapped.\n",
      "The 5th discontinuous entity in doc_256 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_257 is overlapped.\n",
      "The 12th discontinuous entity in doc_259 is overlapped.\n",
      "The 14th discontinuous entity in doc_259 is overlapped.\n",
      "The 15th discontinuous entity in doc_259 is overlapped.\n",
      "The 19th discontinuous entity in doc_259 is overlapped.\n",
      "The 22th discontinuous entity in doc_259 is overlapped.\n",
      "The 23th discontinuous entity in doc_259 is overlapped.\n",
      "The 24th discontinuous entity in doc_259 is overlapped.\n",
      "The 31th discontinuous entity in doc_261 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_265 is overlapped.\n",
      "The 22th discontinuous entity in doc_265 is non-overlapped.\n",
      "The 8th discontinuous entity in doc_266 is non-overlapped.\n",
      "The 11th discontinuous entity in doc_268 is overlapped.\n",
      "The 2th discontinuous entity in doc_270 is overlapped.\n",
      "The 3th discontinuous entity in doc_270 is overlapped.\n",
      "The 4th discontinuous entity in doc_270 is overlapped.\n",
      "The 9th discontinuous entity in doc_270 is non-overlapped.\n",
      "The 10th discontinuous entity in doc_270 is non-overlapped.\n",
      "The 21th discontinuous entity in doc_270 is overlapped.\n",
      "The 2th discontinuous entity in doc_279 is non-overlapped.\n",
      "The 0th discontinuous entity in doc_281 is non-overlapped.\n",
      "The 3th discontinuous entity in doc_281 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_282 is overlapped.\n",
      "The 3th discontinuous entity in doc_282 is overlapped.\n",
      "The 7th discontinuous entity in doc_282 is overlapped.\n",
      "The 14th discontinuous entity in doc_282 is overlapped.\n",
      "The 22th discontinuous entity in doc_282 is overlapped.\n",
      "The 2th discontinuous entity in doc_283 is overlapped.\n",
      "The 6th discontinuous entity in doc_283 is overlapped.\n",
      "The 14th discontinuous entity in doc_285 is overlapped.\n",
      "The 15th discontinuous entity in doc_285 is overlapped.\n",
      "The 16th discontinuous entity in doc_285 is overlapped.\n",
      "The 1th discontinuous entity in doc_288 is overlapped.\n",
      "The 2th discontinuous entity in doc_288 is overlapped.\n",
      "The 4th discontinuous entity in doc_292 is overlapped.\n",
      "The 18th discontinuous entity in doc_294 is overlapped.\n",
      "The 25th discontinuous entity in doc_294 is non-overlapped.\n",
      "The 4th discontinuous entity in doc_297 is overlapped.\n",
      "The 2th discontinuous entity in doc_298 is non-overlapped.\n",
      "The 4th discontinuous entity in doc_299 is non-overlapped.\n",
      "The 21th discontinuous entity in doc_299 is non-overlapped.\n",
      "The 1th discontinuous entity in doc_302 is non-overlapped.\n",
      "The 11th discontinuous entity in doc_304 is overlapped.\n",
      "The 7th discontinuous entity in doc_309 is overlapped.\n",
      "The 22th discontinuous entity in doc_309 is non-overlapped.\n",
      "The 23th discontinuous entity in doc_309 is non-overlapped.\n",
      "The 34th discontinuous entity in doc_309 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_312 is non-overlapped.\n",
      "The 3th discontinuous entity in doc_315 is overlapped.\n",
      "The 4th discontinuous entity in doc_315 is overlapped.\n",
      "The 3th discontinuous entity in doc_316 is non-overlapped.\n",
      "The 7th discontinuous entity in doc_317 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_319 is non-overlapped.\n",
      "The 1th discontinuous entity in doc_320 is non-overlapped.\n",
      "The 5th discontinuous entity in doc_320 is non-overlapped.\n",
      "The 0th discontinuous entity in doc_321 is overlapped.\n",
      "The 8th discontinuous entity in doc_321 is overlapped.\n",
      "The 10th discontinuous entity in doc_321 is overlapped.\n",
      "The 11th discontinuous entity in doc_321 is overlapped.\n",
      "The 18th discontinuous entity in doc_321 is non-overlapped.\n",
      "The 1th discontinuous entity in doc_323 is non-overlapped.\n",
      "The 12th discontinuous entity in doc_323 is overlapped.\n",
      "The 13th discontinuous entity in doc_323 is overlapped.\n",
      "The 14th discontinuous entity in doc_323 is overlapped.\n",
      "The 3th discontinuous entity in doc_325 is overlapped.\n",
      "The 4th discontinuous entity in doc_326 is non-overlapped.\n",
      "The 5th discontinuous entity in doc_329 is overlapped.\n",
      "The 7th discontinuous entity in doc_329 is overlapped.\n",
      "The 3th discontinuous entity in doc_331 is non-overlapped.\n",
      "The 10th discontinuous entity in doc_337 is overlapped.\n",
      "The 11th discontinuous entity in doc_337 is overlapped.\n",
      "The 12th discontinuous entity in doc_337 is overlapped.\n",
      "The 23th discontinuous entity in doc_337 is overlapped.\n",
      "The 7th discontinuous entity in doc_339 is non-overlapped.\n",
      "The 8th discontinuous entity in doc_339 is non-overlapped.\n",
      "The 4th discontinuous entity in doc_340 is overlapped.\n",
      "The 5th discontinuous entity in doc_340 is overlapped.\n",
      "The 6th discontinuous entity in doc_340 is overlapped.\n",
      "The 8th discontinuous entity in doc_340 is overlapped.\n",
      "The 15th discontinuous entity in doc_340 is non-overlapped.\n",
      "The 16th discontinuous entity in doc_342 is overlapped.\n",
      "The 19th discontinuous entity in doc_342 is overlapped.\n",
      "The 8th discontinuous entity in doc_344 is overlapped.\n",
      "The 9th discontinuous entity in doc_344 is overlapped.\n",
      "The 4th discontinuous entity in doc_345 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_346 is overlapped.\n",
      "The 1th discontinuous entity in doc_347 is non-overlapped.\n",
      "The 5th discontinuous entity in doc_349 is overlapped.\n",
      "The 20th discontinuous entity in doc_349 is overlapped.\n",
      "The 21th discontinuous entity in doc_349 is overlapped.\n",
      "The 4th discontinuous entity in doc_350 is overlapped.\n",
      "The 8th discontinuous entity in doc_350 is non-overlapped.\n",
      "The 10th discontinuous entity in doc_350 is overlapped.\n",
      "The 11th discontinuous entity in doc_350 is overlapped.\n",
      "The 21th discontinuous entity in doc_350 is overlapped.\n",
      "The 22th discontinuous entity in doc_350 is overlapped.\n",
      "The 1th discontinuous entity in doc_363 is non-overlapped.\n",
      "The 8th discontinuous entity in doc_363 is overlapped.\n",
      "The 10th discontinuous entity in doc_364 is overlapped.\n",
      "The 3th discontinuous entity in doc_366 is overlapped.\n",
      "The 24th discontinuous entity in doc_366 is overlapped.\n",
      "The 28th discontinuous entity in doc_366 is overlapped.\n",
      "The 6th discontinuous entity in doc_368 is overlapped.\n",
      "The 7th discontinuous entity in doc_368 is overlapped.\n",
      "The 8th discontinuous entity in doc_368 is overlapped.\n",
      "The 10th discontinuous entity in doc_376 is overlapped.\n",
      "The 6th discontinuous entity in doc_378 is overlapped.\n",
      "The 7th discontinuous entity in doc_378 is overlapped.\n",
      "The 11th discontinuous entity in doc_378 is non-overlapped.\n",
      "The 13th discontinuous entity in doc_378 is overlapped.\n",
      "The 3th discontinuous entity in doc_382 is non-overlapped.\n",
      "The 1th discontinuous entity in doc_383 is overlapped.\n",
      "The 2th discontinuous entity in doc_383 is overlapped.\n",
      "The 3th discontinuous entity in doc_383 is non-overlapped.\n",
      "The 4th discontinuous entity in doc_383 is overlapped.\n",
      "The 5th discontinuous entity in doc_383 is overlapped.\n",
      "The 6th discontinuous entity in doc_383 is overlapped.\n",
      "The 9th discontinuous entity in doc_383 is non-overlapped.\n",
      "The 12th discontinuous entity in doc_385 is overlapped.\n",
      "The 13th discontinuous entity in doc_385 is non-overlapped.\n",
      "The 20th discontinuous entity in doc_385 is non-overlapped.\n",
      "The 9th discontinuous entity in doc_386 is overlapped.\n",
      "The 10th discontinuous entity in doc_386 is overlapped.\n",
      "The 24th discontinuous entity in doc_386 is non-overlapped.\n",
      "The 12th discontinuous entity in doc_388 is overlapped.\n",
      "The 1th discontinuous entity in doc_389 is non-overlapped.\n",
      "The 16th discontinuous entity in doc_389 is overlapped.\n",
      "The 12th discontinuous entity in doc_397 is non-overlapped.\n",
      "The 3th discontinuous entity in doc_400 is non-overlapped.\n",
      "The 5th discontinuous entity in doc_400 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_401 is non-overlapped.\n",
      "The 8th discontinuous entity in doc_401 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_403 is non-overlapped.\n",
      "The 9th discontinuous entity in doc_403 is overlapped.\n",
      "The 14th discontinuous entity in doc_403 is non-overlapped.\n",
      "The 15th discontinuous entity in doc_403 is overlapped.\n",
      "The 16th discontinuous entity in doc_403 is overlapped.\n",
      "The 18th discontinuous entity in doc_403 is non-overlapped.\n",
      "The 1th discontinuous entity in doc_406 is non-overlapped.\n",
      "The 3th discontinuous entity in doc_406 is overlapped.\n",
      "The 4th discontinuous entity in doc_406 is overlapped.\n",
      "The 14th discontinuous entity in doc_406 is overlapped.\n",
      "The 15th discontinuous entity in doc_406 is overlapped.\n",
      "The 13th discontinuous entity in doc_407 is overlapped.\n",
      "The 5th discontinuous entity in doc_410 is overlapped.\n",
      "The 15th discontinuous entity in doc_411 is overlapped.\n",
      "The 5th discontinuous entity in doc_412 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_412 is non-overlapped.\n",
      "The 14th discontinuous entity in doc_412 is non-overlapped.\n",
      "The 17th discontinuous entity in doc_414 is overlapped.\n",
      "The 18th discontinuous entity in doc_414 is overlapped.\n",
      "The 8th discontinuous entity in doc_417 is overlapped.\n",
      "The 12th discontinuous entity in doc_417 is overlapped.\n",
      "The 24th discontinuous entity in doc_417 is overlapped.\n",
      "The 48th discontinuous entity in doc_417 is overlapped.\n",
      "The 3th discontinuous entity in doc_419 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_421 is overlapped.\n",
      "The 7th discontinuous entity in doc_421 is overlapped.\n",
      "The 8th discontinuous entity in doc_421 is overlapped.\n",
      "The 12th discontinuous entity in doc_421 is non-overlapped.\n",
      "The 13th discontinuous entity in doc_421 is non-overlapped.\n",
      "The 7th discontinuous entity in doc_423 is overlapped.\n",
      "The 21th discontinuous entity in doc_427 is overlapped.\n",
      "The 22th discontinuous entity in doc_427 is overlapped.\n",
      "The 8th discontinuous entity in doc_430 is overlapped.\n",
      "The 3th discontinuous entity in doc_432 is overlapped.\n",
      "The 4th discontinuous entity in doc_432 is non-overlapped.\n",
      "The 7th discontinuous entity in doc_432 is non-overlapped.\n",
      "The 8th discontinuous entity in doc_432 is non-overlapped.\n",
      "The 13th discontinuous entity in doc_432 is non-overlapped.\n",
      "The 16th discontinuous entity in doc_432 is non-overlapped.\n",
      "The 18th discontinuous entity in doc_432 is overlapped.\n",
      "The 1th discontinuous entity in doc_437 is non-overlapped.\n",
      "The 4th discontinuous entity in doc_443 is overlapped.\n",
      "The 5th discontinuous entity in doc_443 is overlapped.\n",
      "The 4th discontinuous entity in doc_445 is overlapped.\n",
      "The 5th discontinuous entity in doc_445 is overlapped.\n",
      "The 8th discontinuous entity in doc_445 is non-overlapped.\n",
      "The 11th discontinuous entity in doc_445 is overlapped.\n",
      "The 12th discontinuous entity in doc_445 is overlapped.\n",
      "The 13th discontinuous entity in doc_445 is overlapped.\n",
      "The 22th discontinuous entity in doc_445 is non-overlapped.\n",
      "The 7th discontinuous entity in doc_446 is overlapped.\n",
      "The 8th discontinuous entity in doc_446 is overlapped.\n",
      "The 9th discontinuous entity in doc_446 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_447 is overlapped.\n",
      "The 4th discontinuous entity in doc_449 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_450 is overlapped.\n",
      "The 3th discontinuous entity in doc_450 is overlapped.\n",
      "The 4th discontinuous entity in doc_450 is overlapped.\n",
      "The 5th discontinuous entity in doc_450 is overlapped.\n",
      "The 6th discontinuous entity in doc_450 is overlapped.\n",
      "The 9th discontinuous entity in doc_450 is overlapped.\n",
      "The 10th discontinuous entity in doc_450 is overlapped.\n",
      "The 15th discontinuous entity in doc_450 is overlapped.\n",
      "The 3th discontinuous entity in doc_451 is overlapped.\n",
      "The 10th discontinuous entity in doc_451 is overlapped.\n",
      "The 15th discontinuous entity in doc_451 is non-overlapped.\n",
      "The 13th discontinuous entity in doc_452 is overlapped.\n",
      "The 10th discontinuous entity in doc_454 is overlapped.\n",
      "The 11th discontinuous entity in doc_454 is overlapped.\n",
      "The 2th discontinuous entity in doc_456 is non-overlapped.\n",
      "The 7th discontinuous entity in doc_456 is overlapped.\n",
      "The 12th discontinuous entity in doc_456 is overlapped.\n",
      "The 6th discontinuous entity in doc_461 is overlapped.\n",
      "The 6th discontinuous entity in doc_464 is overlapped.\n",
      "The 19th discontinuous entity in doc_464 is overlapped.\n",
      "The 20th discontinuous entity in doc_464 is overlapped.\n",
      "The 21th discontinuous entity in doc_464 is overlapped.\n",
      "The 22th discontinuous entity in doc_464 is overlapped.\n",
      "The 16th discontinuous entity in doc_466 is overlapped.\n",
      "The 5th discontinuous entity in doc_468 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_471 is overlapped.\n",
      "The 4th discontinuous entity in doc_471 is overlapped.\n",
      "The 6th discontinuous entity in doc_471 is overlapped.\n",
      "The 18th discontinuous entity in doc_472 is non-overlapped.\n",
      "The 3th discontinuous entity in doc_473 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_476 is overlapped.\n",
      "The 7th discontinuous entity in doc_476 is overlapped.\n",
      "The 8th discontinuous entity in doc_476 is overlapped.\n",
      "The 1th discontinuous entity in doc_479 is non-overlapped.\n",
      "The 5th discontinuous entity in doc_480 is overlapped.\n",
      "The 6th discontinuous entity in doc_480 is overlapped.\n",
      "The 7th discontinuous entity in doc_480 is overlapped.\n",
      "The 8th discontinuous entity in doc_480 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_487 is non-overlapped.\n",
      "The 18th discontinuous entity in doc_488 is non-overlapped.\n",
      "The 3th discontinuous entity in doc_489 is overlapped.\n",
      "The 5th discontinuous entity in doc_489 is non-overlapped.\n",
      "The 2th discontinuous entity in doc_491 is non-overlapped.\n",
      "The 7th discontinuous entity in doc_492 is overlapped.\n",
      "The 4th discontinuous entity in doc_499 is overlapped.\n",
      "The 3th discontinuous entity in doc_505 is overlapped.\n",
      "The 4th discontinuous entity in doc_505 is overlapped.\n",
      "The 5th discontinuous entity in doc_505 is non-overlapped.\n",
      "The 14th discontinuous entity in doc_506 is overlapped.\n",
      "The 6th discontinuous entity in doc_507 is overlapped.\n",
      "The 12th discontinuous entity in doc_509 is overlapped.\n",
      "The 14th discontinuous entity in doc_509 is overlapped.\n",
      "The 17th discontinuous entity in doc_509 is overlapped.\n",
      "The 18th discontinuous entity in doc_509 is overlapped.\n",
      "The 10th discontinuous entity in doc_511 is overlapped.\n",
      "The 8th discontinuous entity in doc_513 is overlapped.\n",
      "The 3th discontinuous entity in doc_514 is overlapped.\n",
      "The 11th discontinuous entity in doc_514 is non-overlapped.\n",
      "The 13th discontinuous entity in doc_514 is overlapped.\n",
      "The 4th discontinuous entity in doc_517 is non-overlapped.\n",
      "The 5th discontinuous entity in doc_517 is overlapped.\n",
      "The 6th discontinuous entity in doc_517 is overlapped.\n",
      "The 18th discontinuous entity in doc_517 is non-overlapped.\n",
      "The 4th discontinuous entity in doc_519 is overlapped.\n",
      "The 17th discontinuous entity in doc_519 is overlapped.\n",
      "The 18th discontinuous entity in doc_519 is overlapped.\n",
      "The 4th discontinuous entity in doc_520 is overlapped.\n",
      "The 5th discontinuous entity in doc_520 is overlapped.\n",
      "The 6th discontinuous entity in doc_520 is overlapped.\n",
      "The 2th discontinuous entity in doc_522 is overlapped.\n",
      "The 6th discontinuous entity in doc_522 is overlapped.\n",
      "The 11th discontinuous entity in doc_523 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_524 is overlapped.\n",
      "The 2th discontinuous entity in doc_525 is non-overlapped.\n",
      "The 9th discontinuous entity in doc_528 is non-overlapped.\n",
      "The 9th discontinuous entity in doc_532 is non-overlapped.\n",
      "The 10th discontinuous entity in doc_535 is non-overlapped.\n",
      "The 11th discontinuous entity in doc_535 is overlapped.\n",
      "The 36th discontinuous entity in doc_535 is overlapped.\n",
      "The 37th discontinuous entity in doc_535 is overlapped.\n",
      "The 3th discontinuous entity in doc_539 is overlapped.\n",
      "The 4th discontinuous entity in doc_539 is overlapped.\n",
      "The 4th discontinuous entity in doc_542 is non-overlapped.\n",
      "The 10th discontinuous entity in doc_542 is overlapped.\n",
      "The 7th discontinuous entity in doc_545 is non-overlapped.\n",
      "The 22th discontinuous entity in doc_545 is overlapped.\n",
      "The 18th discontinuous entity in doc_550 is overlapped.\n",
      "The 3th discontinuous entity in doc_553 is non-overlapped.\n",
      "The 8th discontinuous entity in doc_556 is non-overlapped.\n",
      "The 10th discontinuous entity in doc_556 is non-overlapped.\n",
      "The 13th discontinuous entity in doc_556 is non-overlapped.\n",
      "The 10th discontinuous entity in doc_558 is overlapped.\n",
      "The 3th discontinuous entity in doc_560 is non-overlapped.\n",
      "The 30th discontinuous entity in doc_562 is overlapped.\n",
      "The 41th discontinuous entity in doc_562 is overlapped.\n",
      "The 42th discontinuous entity in doc_562 is overlapped.\n",
      "The 2th discontinuous entity in doc_565 is overlapped.\n",
      "The 3th discontinuous entity in doc_565 is overlapped.\n",
      "The 1th discontinuous entity in doc_568 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_574 is overlapped.\n",
      "The 7th discontinuous entity in doc_574 is overlapped.\n",
      "The 9th discontinuous entity in doc_575 is non-overlapped.\n",
      "The 30th discontinuous entity in doc_575 is non-overlapped.\n",
      "The 27th discontinuous entity in doc_576 is non-overlapped.\n",
      "The 4th discontinuous entity in doc_579 is non-overlapped.\n",
      "The 6th discontinuous entity in doc_579 is non-overlapped.\n",
      "The 16th discontinuous entity in doc_580 is overlapped.\n",
      "The 17th discontinuous entity in doc_580 is overlapped.\n",
      "The 18th discontinuous entity in doc_580 is overlapped.\n",
      "The 3th discontinuous entity in doc_587 is overlapped.\n",
      "The 10th discontinuous entity in doc_587 is overlapped.\n",
      "The 0th discontinuous entity in doc_588 is overlapped.\n",
      "The 2th discontinuous entity in doc_588 is overlapped.\n",
      "The 19th discontinuous entity in doc_588 is non-overlapped.\n",
      "The 4th discontinuous entity in doc_589 is overlapped.\n",
      "The 5th discontinuous entity in doc_589 is overlapped.\n",
      "The 6th discontinuous entity in doc_589 is overlapped.\n",
      "The 2th discontinuous entity in doc_594 is non-overlapped.\n"
     ]
    }
   ],
   "source": [
    "num_non_overlapped = 0\n",
    "num_overlapped = 0\n",
    "\n",
    "for doc in range(len(train)):\n",
    "    \n",
    "    ner_lists = train[doc]['ner_modified']\n",
    "    \n",
    "    for current_entitiy_idx in range(len(ner_lists)): \n",
    "        \n",
    "        if len(ner_lists[current_entitiy_idx]) == 3: # 2-fragment discontinuous entities\n",
    "\n",
    "            num_nonoverlap_fragments = num_nonoverlap_fragments_current_entity(ner_lists, current_entitiy_idx)\n",
    "\n",
    "            if not check_cur_entity_overlap(ner_lists, current_entitiy_idx, num_nonoverlap_fragments):\n",
    "                print(f\"The {current_entitiy_idx}th discontinuous entity in doc_{doc} is non-overlapped.\")\n",
    "                num_non_overlapped += 1\n",
    "            else:\n",
    "                print(f\"The {current_entitiy_idx}th discontinuous entity in doc_{doc} is overlapped.\")\n",
    "                num_overlapped += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4315bc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_non_overlapped is 173 and num_overlapped is 310\n"
     ]
    }
   ],
   "source": [
    "print(f'num_non_overlapped is {num_non_overlapped} and num_overlapped is {num_overlapped}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82da3b0a",
   "metadata": {},
   "source": [
    "# Check whether two fragments are overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0465c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overlap(fragment1, fragment2):\n",
    "    \n",
    "    # Extract the left and right positions of each fragment\n",
    "    left1, right1 = fragment1\n",
    "    left2, right2 = fragment2\n",
    "\n",
    "    # Check for overlap\n",
    "    if right1 < left2 or right2 < left1:\n",
    "        return False  # Non-overlapping fragments\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07348755",
   "metadata": {},
   "source": [
    "# Rule 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b81658a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the 2nd fragment to the right of the 1st fragment\n",
    "\n",
    "def modify_tokens_rule_1(tokens, ner_lists, current_entitiy_idx):\n",
    "    \n",
    "    # All tokens before (including) the last token of the 1st fragment\n",
    "    tokens_before_1st_fragment = tokens[:ner_lists[current_entitiy_idx][0][1] + 1]\n",
    "    # All tokens of the 2nd fragment\n",
    "    tokens_2nd_fragment = tokens[ner_lists[current_entitiy_idx][1][0]:ner_lists[current_entitiy_idx][1][1] + 1] \n",
    "    # All tokens after (including) the 1st token of the 2nd fragment\n",
    "    tokens_after_2nd_fragment = tokens[ner_lists[current_entitiy_idx][0][1] + 1:]\n",
    "    \n",
    "    new_tokens = tokens_before_1st_fragment + tokens_2nd_fragment + tokens_after_2nd_fragment\n",
    "    \n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b00c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_offsets_rule_1(ner_lists, current_entitiy_idx):\n",
    "    \n",
    "    # Number of tokens of the 2nd fragment\n",
    "    len_2nd_fragment = ner_lists[current_entitiy_idx][1][1] - ner_lists[current_entitiy_idx][1][0] + 1\n",
    "\n",
    "    last_token_pos_1st_fragment = ner_lists[current_entitiy_idx][0][1]\n",
    "    \n",
    "    # Modify offsets for the current discontinuous entity \n",
    "    ner_lists[current_entitiy_idx] = [[ner_lists[current_entitiy_idx][0][0], \n",
    "                                       ner_lists[current_entitiy_idx][0][1] + len_2nd_fragment], \n",
    "                                      ner_lists[current_entitiy_idx][-1]]\n",
    "\n",
    "    for idx in range(len(ner_lists)): \n",
    "\n",
    "        if idx != current_entitiy_idx:\n",
    "\n",
    "            for k in range(len(ner_lists[idx]) - 1):\n",
    "                \n",
    "                if (ner_lists[idx][k][0] > last_token_pos_1st_fragment \n",
    "                and ner_lists[idx][k][1] > last_token_pos_1st_fragment):\n",
    "                    ner_lists[idx][k][0] += len_2nd_fragment\n",
    "                    ner_lists[idx][k][1] += len_2nd_fragment   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90f3d48",
   "metadata": {},
   "source": [
    "# Rule 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "785a881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the 1st fragment to the left of the 2nd fragment\n",
    "\n",
    "def modify_tokens_rule_2(tokens, ner_lists, current_entitiy_idx):\n",
    "    \n",
    "    # All tokens before (excluding) the 1st token of the 2nd fragment\n",
    "    tokens_before_2nd_fragment = tokens[:ner_lists[current_entitiy_idx][1][0]]\n",
    "    # All tokens of the 1st fragment\n",
    "    tokens_1st_fragment = tokens[ner_lists[current_entitiy_idx][0][0]:ner_lists[current_entitiy_idx][0][1] + 1] \n",
    "    # All tokens after (including) the 1st token of the 2nd fragment\n",
    "    tokens_after_2nd_fragment = tokens[ner_lists[current_entitiy_idx][1][0]:]\n",
    "    \n",
    "    new_tokens = tokens_before_2nd_fragment + tokens_1st_fragment + tokens_after_2nd_fragment\n",
    "    \n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc176f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_offsets_rule_2(ner_lists, current_entitiy_idx):\n",
    "    \n",
    "    # Number of tokens of the 1st fragment\n",
    "    len_1st_fragment = ner_lists[current_entitiy_idx][0][1] - ner_lists[current_entitiy_idx][0][0] + 1\n",
    "\n",
    "    first_token_pos_2nd_fragment = ner_lists[current_entitiy_idx][1][0]\n",
    "\n",
    "    ner_lists[current_entitiy_idx] = [[ner_lists[current_entitiy_idx][1][0], \n",
    "                                       ner_lists[current_entitiy_idx][1][1] + len_1st_fragment], \n",
    "                                      ner_lists[current_entitiy_idx][-1]]\n",
    "\n",
    "    for idx in range(len(ner_lists)):         \n",
    "\n",
    "        if idx != current_entitiy_idx:    \n",
    "\n",
    "            for k in range(len(ner_lists[idx]) - 1):\n",
    "\n",
    "                if (ner_lists[idx][k][0] >= first_token_pos_2nd_fragment \n",
    "                and ner_lists[idx][k][1] >= first_token_pos_2nd_fragment):\n",
    "                    ner_lists[idx][k][0] += len_1st_fragment\n",
    "                    ner_lists[idx][k][1] += len_1st_fragment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0152b00e",
   "metadata": {},
   "source": [
    "# Modify sentences with 2-fragment discontinuous entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13baf486",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in range(len(train)):\n",
    "    \n",
    "    tokens = train[doc]['sentences_modified'] \n",
    "    # Changing tokens will NOT change train[doc]['sentences_modified'] for *operations* below\n",
    "    ner_lists = train[doc]['ner_modified'] \n",
    "    # Changing ner_lists WILL change train[doc]['ner_modified'] for *operations* below\n",
    "\n",
    "    for current_entitiy_idx in range(len(ner_lists)):\n",
    "\n",
    "        if len(ner_lists[current_entitiy_idx]) == 3:  # 2-fragment discontinuous entities\n",
    "            \n",
    "            interval_1st = ner_lists[current_entitiy_idx][0]\n",
    "            interval_2nd = ner_lists[current_entitiy_idx][1]\n",
    "\n",
    "            switch = 0\n",
    "\n",
    "            for idx in range(len(ner_lists)):\n",
    "\n",
    "                if idx != current_entitiy_idx:\n",
    "\n",
    "                    if len(ner_lists[idx]) == 2: # Continuous entities\n",
    "                        \n",
    "                        interval_cont = ner_lists[idx][0] \n",
    "                        \n",
    "                        if check_overlap(interval_2nd, interval_cont):\n",
    "                            switch = 1\n",
    "                            break\n",
    "                        \n",
    "                        elif check_overlap(interval_1st, interval_cont):\n",
    "                            switch = 3\n",
    "                            break\n",
    "                               \n",
    "                        \n",
    "                    elif len(ner_lists[idx]) == 3: # 2-fragment discontinuous entities\n",
    "                        \n",
    "                        interval_discont_1st = ner_lists[idx][0]\n",
    "                        interval_discont_2nd = ner_lists[idx][1]\n",
    "                                              \n",
    "                        if (check_overlap(interval_2nd, interval_discont_2nd) is True \n",
    "                        and check_overlap(interval_1st, interval_discont_1st) is False):\n",
    "                            switch = 2\n",
    "                            break\n",
    "\n",
    "                        elif (check_overlap(interval_1st, interval_discont_1st) is True \n",
    "                        and check_overlap(interval_2nd, interval_discont_2nd) is False):\n",
    "                            switch = 4\n",
    "                            break                             \n",
    "                            \n",
    "                        elif (check_overlap(interval_2nd, interval_discont_2nd) is True \n",
    "                        and check_overlap(interval_1st, interval_discont_1st) is True\n",
    "                           and interval_1st[1] > interval_discont_1st[1]\n",
    "                           and interval_2nd[0] > interval_discont_1st[0]):\n",
    "                            switch = 5\n",
    "                            break\n",
    "                            \n",
    "                        \n",
    "            if switch == 1 or switch == 2 or switch == 5:\n",
    "\n",
    "                tokens = modify_tokens_rule_1(tokens, ner_lists, current_entitiy_idx)\n",
    "                train[doc]['sentences_modified'] = tokens\n",
    "                \n",
    "                modify_offsets_rule_1(ner_lists, current_entitiy_idx)\n",
    "                \n",
    "                \n",
    "            elif switch == 0 or switch == 3 or switch == 4:\n",
    "\n",
    "                tokens = modify_tokens_rule_2(tokens, ner_lists, current_entitiy_idx)\n",
    "                train[doc]['sentences_modified'] = tokens\n",
    "                \n",
    "                modify_offsets_rule_2(ner_lists, current_entitiy_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d39ffdb",
   "metadata": {},
   "source": [
    "# Sanity check that all entities are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a9bef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in range(len(train)):\n",
    "    \n",
    "    l_modified = []\n",
    "    for i in range(len(train[doc]['ner_modified'])):\n",
    "        l_modified.append(train[doc]['sentences_modified'][train[doc]['ner_modified'][i][0][0]:train[doc]['ner_modified'][i][0][1] + 1])\n",
    "\n",
    "    l_original = []\n",
    "    for i in range(len(train[doc]['ner'])):\n",
    "        if len(train[doc]['ner'][i]) == 2:\n",
    "            l_original.append(train[doc]['sentences'][train[doc]['ner'][i][0][0]:train[doc]['ner'][i][0][1]+1])\n",
    "        elif len(train[doc]['ner'][i]) == 3:\n",
    "            l_original.append(train[doc]['sentences'][train[doc]['ner'][i][0][0]:train[doc]['ner'][i][0][1]+1] + train[doc]['sentences'][train[doc]['ner'][i][1][0]:train[doc]['ner'][i][1][1]+1])\n",
    "        else:\n",
    "            pass        \n",
    "        \n",
    "    if l_modified != l_original:          \n",
    "        print(f'The doc_{doc} needs more examination.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132bef7",
   "metadata": {},
   "source": [
    "# Add relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca3a42fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = '/Users/XA/Desktop/RareDis_Pipeline/Datasets_with_gold_relations/train_re.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0a05ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_re = []\n",
    "for line in open(Path, 'r'):\n",
    "    train_re.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb26dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = '/Users/XA/Desktop/RareDis_Pipeline/Step2_cache_double_labels/train_cache.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7de88233",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = []\n",
    "for line in open(Path, 'r'):\n",
    "    cache.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c9a0f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check key errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "159fad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in range(len(train)):\n",
    "    if not train[doc]['doc_key'] == train_re[doc]['doc'] == cache[doc]['doc']:\n",
    "        print('Document key error happens.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f790fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether all entities are continuous or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39764893",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in range(len(train)):\n",
    "    for i in range(len(train[doc]['ner_modified'])):\n",
    "        if len(train[doc]['ner_modified'][i]) != 2:\n",
    "            print('There are still discontinuous entities.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f07549bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check double labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72e2ccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[15, 15], ['DISEASE', 'SIGN']], [[81, 82], ['DISEASE', 'SYMPTOM', 'SIGN']]]\n"
     ]
    }
   ],
   "source": [
    "def find_lists_same_offsets_diff_types(list_of_lists):\n",
    "    # Maintain a dictionary where keys are offsets and values are sets of types\n",
    "    offset_to_types = {}\n",
    "    for lst in list_of_lists:\n",
    "        offset, type = tuple(lst[0]), lst[1]\n",
    "        if offset not in offset_to_types:\n",
    "            offset_to_types[offset] = set()\n",
    "        offset_to_types[offset].add(type)\n",
    "\n",
    "    # Keep only those entries with more than one type\n",
    "    result = [[list(offset), list(types)] for offset, types in offset_to_types.items() if len(types) > 1]\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "list_of_lists = [[[0, 1], 'RAREDISEASE'],\n",
    "                 [[5, 6], 'DISEASE'],\n",
    "                 [[15, 15], 'DISEASE'],\n",
    "                 [[15, 15], 'SIGN'],\n",
    "                 [[53, 53], 'SYMPTOM'],\n",
    "                 [[60, 60], 'DISEASE'],\n",
    "                 [[70, 77], 'SIGN'],\n",
    "                 [[79, 79], 'SYMPTOM'],\n",
    "                 [[81, 82], 'SIGN'],\n",
    "                 [[81, 82], 'DISEASE'],\n",
    "                 [[81, 82], 'SYMPTOM'],\n",
    "                 [[96, 97], 'SIGN'],\n",
    "                 [[99, 101], 'SIGN']]\n",
    "\n",
    "print(find_lists_same_offsets_diff_types(list_of_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b04ef96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "7\n",
      "19\n",
      "24\n",
      "25\n",
      "28\n",
      "31\n",
      "32\n",
      "35\n",
      "39\n",
      "45\n",
      "50\n",
      "63\n",
      "68\n",
      "69\n",
      "75\n",
      "76\n",
      "79\n",
      "80\n",
      "88\n",
      "92\n",
      "94\n",
      "98\n",
      "101\n",
      "103\n",
      "107\n",
      "111\n",
      "113\n",
      "115\n",
      "118\n",
      "120\n",
      "122\n",
      "127\n",
      "137\n",
      "142\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "150\n",
      "155\n",
      "161\n",
      "164\n",
      "167\n",
      "170\n",
      "171\n",
      "173\n",
      "174\n",
      "181\n",
      "184\n",
      "185\n",
      "189\n",
      "192\n",
      "194\n",
      "195\n",
      "196\n",
      "200\n",
      "205\n",
      "206\n",
      "209\n",
      "215\n",
      "218\n",
      "230\n",
      "239\n",
      "242\n",
      "245\n",
      "251\n",
      "252\n",
      "255\n",
      "256\n",
      "261\n",
      "265\n",
      "266\n",
      "268\n",
      "273\n",
      "274\n",
      "279\n",
      "284\n",
      "287\n",
      "289\n",
      "291\n",
      "295\n",
      "299\n",
      "304\n",
      "306\n",
      "309\n",
      "315\n",
      "316\n",
      "318\n",
      "320\n",
      "323\n",
      "325\n",
      "326\n",
      "329\n",
      "337\n",
      "340\n",
      "345\n",
      "349\n",
      "351\n",
      "355\n",
      "363\n",
      "366\n",
      "368\n",
      "369\n",
      "372\n",
      "376\n",
      "378\n",
      "379\n",
      "381\n",
      "385\n",
      "387\n",
      "388\n",
      "390\n",
      "392\n",
      "397\n",
      "398\n",
      "400\n",
      "403\n",
      "407\n",
      "411\n",
      "412\n",
      "417\n",
      "418\n",
      "420\n",
      "421\n",
      "423\n",
      "430\n",
      "445\n",
      "447\n",
      "449\n",
      "451\n",
      "456\n",
      "458\n",
      "464\n",
      "470\n",
      "472\n",
      "481\n",
      "482\n",
      "490\n",
      "493\n",
      "494\n",
      "496\n",
      "503\n",
      "506\n",
      "507\n",
      "509\n",
      "512\n",
      "514\n",
      "517\n",
      "520\n",
      "522\n",
      "523\n",
      "525\n",
      "528\n",
      "532\n",
      "535\n",
      "536\n",
      "538\n",
      "539\n",
      "545\n",
      "550\n",
      "553\n",
      "555\n",
      "558\n",
      "562\n",
      "567\n",
      "574\n",
      "575\n",
      "576\n",
      "578\n",
      "580\n",
      "583\n",
      "584\n",
      "587\n",
      "588\n",
      "594\n"
     ]
    }
   ],
   "source": [
    "for doc in range(len(train)):\n",
    "    if find_lists_same_offsets_diff_types(train[doc]['ner_modified']) != []:\n",
    "        print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e85ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5777cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2372d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_deleting_discont_morethan2(ner_lists_raw, ner_lists):\n",
    "    \n",
    "    # All indices of discontinuous entities with more than two fragments    \n",
    "    ner_lists_raw_removed = []\n",
    "    for idx in range(len(ner_lists_raw)):\n",
    "        if len(ner_lists_raw[idx]) > 3:\n",
    "            ner_lists_raw_removed.append(idx)\n",
    "\n",
    "    # Create a dictionary to store the names and associated lists\n",
    "    dict_ner_lists_raw = {f\"T{i+1}\": ner_lists_raw[i] for i in range(len(ner_lists_raw))}\n",
    "\n",
    "    # Remove the elements in ner_lists_raw_removed from the dictionary\n",
    "    for idx in ner_lists_raw_removed:\n",
    "        del dict_ner_lists_raw[f\"T{idx+1}\"]\n",
    "\n",
    "    # Convert the dictionary items to a list\n",
    "    items = list(dict_ner_lists_raw.items())\n",
    "\n",
    "    # Create a new dictionary after deleting discontinuous entities with more than two fragments   \n",
    "    new_dict_ner_lists = {}\n",
    "    for k in range(len(ner_lists)):\n",
    "        new_dict_ner_lists[items[k][0]] = ner_lists[k]\n",
    "        \n",
    "    return new_dict_ner_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944a81a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "541970e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mss\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ss' is not defined"
     ]
    }
   ],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd109cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3560c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[doc]['relations'] = []\n",
    "    \n",
    "ner_lists_raw = train[doc]['ner']\n",
    "ner_lists = train[doc]['ner_modified']\n",
    "\n",
    "new_dict_ner_lists = create_dict_deleting_discont_morethan2(ner_lists_raw, ner_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7647efcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T1': [[0, 1], 'RAREDISEASE'],\n",
       " 'T2': [[5, 6], 'DISEASE'],\n",
       " 'T3': [[15, 15], 'DISEASE'],\n",
       " 'T4': [[30, 30], 'DISEASE'],\n",
       " 'T5': [[53, 53], 'SYMPTOM'],\n",
       " 'T6': [[60, 60], 'DISEASE'],\n",
       " 'T7': [[70, 77], 'SIGN'],\n",
       " 'T8': [[79, 79], 'SYMPTOM'],\n",
       " 'T9': [[81, 82], 'SIGN'],\n",
       " 'T10': [[89, 89], 'SIGN'],\n",
       " 'T11': [[96, 97], 'SIGN'],\n",
       " 'T12': [[99, 101], 'SIGN']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict_ner_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3adc0046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache[doc]['remove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ef07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac398aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in range(len(train)):\n",
    "    \n",
    "    train[doc]['relations'] = []\n",
    "    \n",
    "    ner_lists_raw = train[doc]['ner']\n",
    "    ner_lists = train[doc]['ner_modified']\n",
    "        \n",
    "    new_dict_ner_lists = create_dict_deleting_discont_morethan2(ner_lists_raw, ner_lists)\n",
    "    \n",
    "    if cache[doc]['remove'] != []:\n",
    "\n",
    "    \n",
    "    for i in range(len(cache[doc]['remove'])):\n",
    "\n",
    "        a_num = cache[doc]['remove'][i][0][1]\n",
    "        a_name = cache[doc]['remove'][i][0][0]\n",
    "\n",
    "        b_num = cache[doc]['remove'][i][1][1]\n",
    "        b_name = cache[doc]['remove'][i][1][0]\n",
    "\n",
    "        if a_num == 0 and b_num == 0:\n",
    "\n",
    "            chosen_element = random.choice([0, 1])\n",
    "            train[doc]['ner_modified'].remove(new_dict_ner_lists[cache[doc]['remove'][i][chosen_element][0]])\n",
    "\n",
    "            if 'relations' in train_re[doc]:\n",
    "\n",
    "                for j in range(len(train_re[doc]['relations'])):\n",
    "\n",
    "                    for key, value in train_re[doc]['relations'][j].items():\n",
    "\n",
    "                        if value[0] in new_dict_ner_lists and value[1] in new_dict_ner_lists:\n",
    "                            rel_temp = []\n",
    "                            rel_temp += (new_dict_ner_lists[value[0]][0] + new_dict_ner_lists[value[1]][0])\n",
    "                            rel_temp.append(key)\n",
    "\n",
    "                    train[doc]['relations'].append(rel_temp)\n",
    "\n",
    "\n",
    "        elif (a_num == 0 and b_num >= 1) or (b_num == 0 and a_num >= 1):\n",
    "\n",
    "            if a_num == 0:\n",
    "\n",
    "                train[doc]['ner_modified'].remove(new_dict_ner_lists[a_name])\n",
    "\n",
    "            elif b_num == 0:\n",
    "\n",
    "                train[doc]['ner_modified'].remove(new_dict_ner_lists[b_name])\n",
    "\n",
    "\n",
    "            if 'relations' in train_re[doc]:\n",
    "\n",
    "                for j in range(len(train_re[doc]['relations'])):\n",
    "\n",
    "                    for key, value in train_re[doc]['relations'][j].items():\n",
    "\n",
    "                        if value[0] in new_dict_ner_lists and value[1] in new_dict_ner_lists:\n",
    "                            rel_temp = []\n",
    "                            rel_temp += (new_dict_ner_lists[value[0]][0] + new_dict_ner_lists[value[1]][0])\n",
    "                            rel_temp.append(key)\n",
    "                        else:\n",
    "                            pass \n",
    "\n",
    "                    train[doc]['relations'].append(rel_temp)\n",
    "\n",
    "\n",
    "        elif a_num == 1 and b_num == 1:\n",
    "\n",
    "            chosen_element = random.choice([0, 1])\n",
    "            train[doc]['ner_modified'].remove(new_dict_ner_lists[cache[doc]['remove'][i][chosen_element][0]])\n",
    "\n",
    "            if 'relations' in train_re[doc]:\n",
    "\n",
    "                for j in range(len(train_re[doc]['relations'])):\n",
    "\n",
    "                    for key, value in train_re[doc]['relations'][j].items():\n",
    "\n",
    "                        if (value[0] in new_dict_ner_lists\n",
    "                        and value[1] in new_dict_ner_lists\n",
    "                        and value[0] != cache[doc]['remove'][i][chosen_element][0] \n",
    "                        and value[1] != cache[doc]['remove'][i][chosen_element][0]):\n",
    "                            rel_temp = []\n",
    "                            rel_temp += (new_dict_ner_lists[value[0]][0] + new_dict_ner_lists[value[1]][0])\n",
    "                            rel_temp.append(key) \n",
    "\n",
    "                    train[doc]['relations'].append(rel_temp)\n",
    "\n",
    "        else: # (a_num = 1, b_num = N) or (a_num = N, b_num = 1)\n",
    "\n",
    "\n",
    "            if a_num == 1:\n",
    "\n",
    "                train[doc]['ner_modified'].remove(new_dict_ner_lists[a_name])\n",
    "\n",
    "                if 'relations' in train_re[doc]:\n",
    "\n",
    "                    for j in range(len(train_re[doc]['relations'])):\n",
    "\n",
    "                        for key, value in train_re[doc]['relations'][j].items():\n",
    "\n",
    "                            if (value[0] in new_dict_ner_lists\n",
    "                            and value[1] in new_dict_ner_lists \n",
    "                            and value[0] != a_name \n",
    "                            and value[1] != a_name):\n",
    "                                rel_temp = []\n",
    "                                rel_temp += (new_dict_ner_lists[value[0]][0] + new_dict_ner_lists[value[1]][0])\n",
    "                                rel_temp.append(key)\n",
    "          \n",
    "                        train[doc]['relations'].append(rel_temp)\n",
    "\n",
    "            elif b_num == 1:\n",
    "\n",
    "                train[doc]['ner_modified'].remove(new_dict_ner_lists[b_name])\n",
    "\n",
    "                if 'relations' in train_re[doc]:\n",
    "\n",
    "                    for j in range(len(train_re[doc]['relations'])):\n",
    "\n",
    "                        for key, value in train_re[doc]['relations'][j].items():\n",
    "\n",
    "                            if (value[0] in new_dict_ner_lists\n",
    "                            and value[1] in new_dict_ner_lists \n",
    "                            and value[0] != b_name \n",
    "                            and value[1] != b_name):\n",
    "                                rel_temp = []\n",
    "                                rel_temp += (new_dict_ner_lists[value[0]][0] + new_dict_ner_lists[value[1]][0])\n",
    "                                rel_temp.append(key)\n",
    "\n",
    "                        train[doc]['relations'].append(rel_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e669bc8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e903e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check double labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbce605",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in range(len(train)):\n",
    "    if find_lists_same_offsets_diff_types(train[doc]['ner_modified']) != []:\n",
    "        print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff1af4",
   "metadata": {},
   "source": [
    "# Save the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92bfe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_final_final.json', \"w\") as f_out:\n",
    "    for line in train:\n",
    "        f_out.write(json.dumps(line))\n",
    "        f_out.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37642562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
